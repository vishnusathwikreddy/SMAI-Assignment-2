{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.579123Z",
     "iopub.status.busy": "2025-03-18T10:22:11.578841Z",
     "iopub.status.idle": "2025-03-18T10:22:11.582850Z",
     "shell.execute_reply": "2025-03-18T10:22:11.582055Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.579100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.584400Z",
     "iopub.status.busy": "2025-03-18T10:22:11.584080Z",
     "iopub.status.idle": "2025-03-18T10:22:11.596995Z",
     "shell.execute_reply": "2025-03-18T10:22:11.596283Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.584368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def activation(x: torch.Tensor, function: str) -> torch.Tensor:\n",
    "    if function == 'relu':\n",
    "        return torch.where(x > 0, x, torch.zeros_like(x))\n",
    "    elif function == 'sigmoid':\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "    elif function == 'tanh':\n",
    "        return torch.tanh(x)\n",
    "    elif function == 'linear':\n",
    "        return x\n",
    "    elif function == 'softmax':\n",
    "        exp_x = torch.exp(x - torch.max(x, dim=0, keepdim=True)[0])  \n",
    "        return exp_x / torch.sum(exp_x, dim=0, keepdim=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Activation function {function} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.598842Z",
     "iopub.status.busy": "2025-03-18T10:22:11.598515Z",
     "iopub.status.idle": "2025-03-18T10:22:11.609266Z",
     "shell.execute_reply": "2025-03-18T10:22:11.608541Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.598813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def act_der(x: torch.Tensor, function: str) -> torch.Tensor:\n",
    "    if function == 'relu':\n",
    "        return (x > 0).float()\n",
    "    elif function == 'sigmoid':\n",
    "        sig = activation(x, 'sigmoid')\n",
    "        return sig * (1 - sig)\n",
    "    elif function == 'tanh':\n",
    "        return 1 - activation(x, 'tanh').pow(2)\n",
    "    elif function == 'linear':\n",
    "        return torch.ones_like(x)\n",
    "    elif function == 'softmax':\n",
    "        # For softmax, we don't calculate the derivative directly in backprop\n",
    "        # Instead, we use the loss derivative which already accounts for softmax derivative\n",
    "        return torch.ones_like(x)\n",
    "    else:\n",
    "        raise ValueError(f\"Activation function {function} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.610693Z",
     "iopub.status.busy": "2025-03-18T10:22:11.610381Z",
     "iopub.status.idle": "2025-03-18T10:22:11.622078Z",
     "shell.execute_reply": "2025-03-18T10:22:11.621352Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.610666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss(gt: torch.Tensor, pred: torch.Tensor, function: str) -> torch.Tensor:\n",
    "    if gt.device != pred.device:\n",
    "        gt = gt.to(pred.device)\n",
    "        \n",
    "    if function == 'mse':\n",
    "        return torch.mean((pred - gt).pow(2))\n",
    "    elif function == 'bce':\n",
    "        return -torch.mean(gt * torch.log(pred + 1e-7) + (1 - gt) * torch.log(1 - pred + 1e-7))\n",
    "    elif function == 'ce':  # Cross-entropy loss for multi-class classification\n",
    "        return -torch.mean(torch.sum(gt * torch.log(pred + 1e-7), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.622986Z",
     "iopub.status.busy": "2025-03-18T10:22:11.622735Z",
     "iopub.status.idle": "2025-03-18T10:22:11.634355Z",
     "shell.execute_reply": "2025-03-18T10:22:11.633794Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.622966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss_der(gt: torch.Tensor, pred: torch.Tensor, function: str) -> torch.Tensor:\n",
    "    if gt.device != pred.device:\n",
    "        gt = gt.to(pred.device)\n",
    "        \n",
    "    if function == 'mse':\n",
    "        return 2 * (pred - gt) / gt.size(1)\n",
    "    elif function == 'bce':\n",
    "        return -gt / (pred + 1e-7) + (1 - gt) / (1 - pred + 1e-7)\n",
    "    elif function == 'ce':\n",
    "        # For cross-entropy loss with softmax, the derivative simplifies to (pred - gt)\n",
    "        # when each sample has only one correct class\n",
    "        return (pred - gt) / gt.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.729870Z",
     "iopub.status.busy": "2025-03-18T10:22:11.729667Z",
     "iopub.status.idle": "2025-03-18T10:22:11.756181Z",
     "shell.execute_reply": "2025-03-18T10:22:11.755418Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.729852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.layers = []\n",
    "        self.z_list = []\n",
    "        self.a_list = []\n",
    "        self.device = device\n",
    "\n",
    "    def add_layer(self, input_size: int, output_size: int, activation: str):\n",
    "        # Initialize weights using He initialization for ReLU or Xavier for sigmoid/tanh\n",
    "        if activation == 'relu':\n",
    "            w = torch.randn(output_size, input_size, device=self.device) * torch.sqrt(torch.tensor(2.0 / input_size, device=self.device))\n",
    "        else:\n",
    "            w = torch.randn(output_size, input_size, device=self.device) * torch.sqrt(torch.tensor(1.0 / input_size, device=self.device))\n",
    "            \n",
    "        b = torch.zeros(output_size, 1, device=self.device)\n",
    "        self.layers.append([w, b, activation])\n",
    "        self.z_list.append(None)\n",
    "        self.a_list.append(None)\n",
    "\n",
    "    def forwardprop(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        current_input = x.to(self.device)  \n",
    "        for i in range(len(self.layers)):\n",
    "            w, b, activation_func = self.layers[i]\n",
    "            z = torch.mm(w, current_input) + b\n",
    "            self.z_list[i] = z\n",
    "            self.a_list[i] = activation(z, activation_func)\n",
    "            current_input = self.a_list[i]\n",
    "        return self.a_list[-1]\n",
    "\n",
    "    def backprop(self, x: torch.Tensor, y: torch.Tensor, loss_function: str, learning_rate: float = 0.01):\n",
    "        m = x.size(1)  \n",
    "        self.forwardprop(x)\n",
    "        \n",
    "        dz = loss_der(y, self.a_list[-1], loss_function)\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            w, b, activation_func = self.layers[i]\n",
    "            a_prev = self.a_list[i-1] if i > 0 else x\n",
    "            \n",
    "            # If the last layer uses softmax with cross-entropy, dz is already computed correctly\n",
    "            if i == len(self.layers)-1 and activation_func == 'softmax' and loss_function == 'ce':\n",
    "                # Skip multiplying by activation derivative - already accounted for in cross-entropy derivative\n",
    "                pass\n",
    "            else:\n",
    "                dz = dz * act_der(self.z_list[i], activation_func)\n",
    "            \n",
    "            dw = (1/m) * torch.mm(dz, a_prev.T)\n",
    "            db = (1/m) * torch.sum(dz, dim=1, keepdim=True)\n",
    "            \n",
    "            self.layers[i][0] = w - learning_rate * dw\n",
    "            self.layers[i][1] = b - learning_rate * db\n",
    "            \n",
    "            if i > 0:\n",
    "                dz = torch.mm(w.T, dz)\n",
    "\n",
    "    def train(self, X: torch.Tensor, y: torch.Tensor, epochs: int = 100, \n",
    "             batch_size: int = 32, learning_rate: float = 0.01, \n",
    "             loss_function: str = 'mse', optimizer: str = 'Mini_Batch', verbose: bool = True):\n",
    "        n_samples = X.size(1)  \n",
    "        \n",
    "        X = X.to(self.device) \n",
    "        y = y.to(self.device)  \n",
    "        \n",
    "        epoch_losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0.0\n",
    "            perm = torch.randperm(n_samples, device=self.device)\n",
    "            X_shuffled = X[:, perm]\n",
    "            y_shuffled = y[:, perm]  \n",
    "            \n",
    "            if optimizer == 'Batch':\n",
    "                # Process all samples at once\n",
    "                pred = self.forwardprop(X_shuffled)\n",
    "                batch_loss = loss(y_shuffled, pred, loss_function)\n",
    "                total_loss += batch_loss.item()\n",
    "                self.backprop(X_shuffled, y_shuffled, loss_function, learning_rate)\n",
    "            \n",
    "            elif optimizer == 'SGD':\n",
    "                # Stochastic Gradient Descent - process one sample at a time\n",
    "                for i in range(n_samples):\n",
    "                    X_sample = X_shuffled[:, i:i+1]  # Get a single sample\n",
    "                    y_sample = y_shuffled[:, i:i+1]  # Get corresponding label\n",
    "                    \n",
    "                    pred = self.forwardprop(X_sample)\n",
    "                    sample_loss = loss(y_sample, pred, loss_function)\n",
    "                    total_loss += sample_loss.item()\n",
    "                    \n",
    "                    self.backprop(X_sample, y_sample, loss_function, learning_rate)\n",
    "                \n",
    "                total_loss = total_loss / n_samples  # Average the loss over samples\n",
    "            \n",
    "            else:  # Mini_Batch (default)\n",
    "                n_batches = (n_samples + batch_size - 1) // batch_size\n",
    "                \n",
    "                for batch in range(n_batches):\n",
    "                    start_idx = batch * batch_size\n",
    "                    end_idx = min((batch + 1) * batch_size, n_samples)\n",
    "                    \n",
    "                    X_batch = X_shuffled[:, start_idx:end_idx]\n",
    "                    y_batch = y_shuffled[:, start_idx:end_idx]\n",
    "                    \n",
    "                    pred = self.forwardprop(X_batch)\n",
    "                    batch_loss = loss(y_batch, pred, loss_function)\n",
    "                    total_loss += batch_loss.item()\n",
    "                    \n",
    "                    self.backprop(X_batch, y_batch, loss_function, learning_rate)\n",
    "                \n",
    "                total_loss = total_loss / n_batches  # Average loss over batches\n",
    "            \n",
    "            epoch_losses.append(total_loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "                \n",
    "        return epoch_losses  # Return the loss history\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forwardprop(X)\n",
    "\n",
    "    def evaluate(self, X: torch.Tensor, y: torch.Tensor, loss_function: str = 'mse') -> torch.Tensor:\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        pred = self.forwardprop(X)\n",
    "        return loss(y, pred, loss_function)\n",
    "    \n",
    "    def accuracy(self, X: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        pred = self.forwardprop(X)\n",
    "        pred_classes = torch.argmax(pred, dim=0)\n",
    "        true_classes = torch.argmax(y, dim=0)\n",
    "        \n",
    "        correct = (pred_classes == true_classes).float().sum()\n",
    "        total = y.size(1)\n",
    "        \n",
    "        return (correct / total).item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.757370Z",
     "iopub.status.busy": "2025-03-18T10:22:11.757171Z",
     "iopub.status.idle": "2025-03-18T10:22:11.772925Z",
     "shell.execute_reply": "2025-03-18T10:22:11.772268Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.757352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.774869Z",
     "iopub.status.busy": "2025-03-18T10:22:11.774587Z",
     "iopub.status.idle": "2025-03-18T10:22:11.788061Z",
     "shell.execute_reply": "2025-03-18T10:22:11.787260Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.774848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data loading and preparation functions\n",
    "def load_images(image_dir=\"/kaggle/input/smai-symbol-data/images/\"):\n",
    "    if os.path.exists(\"symbols_images.npy\"):\n",
    "        print(\"Loading cached images...\")\n",
    "        images = np.load(\"symbols_images.npy\", allow_pickle=True)\n",
    "        if len(images) > 0:\n",
    "            print(f\"Successfully loaded {len(images)} cached images.\")\n",
    "            return images\n",
    "        else:\n",
    "            print(\"Cached images file is empty. Reloading from directory...\")\n",
    "    \n",
    "    print(\"Loading images from directory...\")\n",
    "    image_paths = glob.glob(image_dir + \"*.png\")\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(f\"No PNG images found in directory: {image_dir}\")\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} image files.\")\n",
    "    \n",
    "    def extract_number(path):\n",
    "        match = re.search(r\"(\\d+)\\.png$\", path)\n",
    "        return int(match.group(1)) if match else float('inf')\n",
    "    \n",
    "    image_paths = sorted(image_paths, key=extract_number)\n",
    "    \n",
    "    import cv2\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load image: {path}\")\n",
    "            continue\n",
    "        images.append(img)\n",
    "    \n",
    "    if not images:\n",
    "        raise ValueError(\"No images were successfully loaded!\")\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    print(f\"Successfully loaded {len(images)} images.\")\n",
    "    \n",
    "    # Save images for future use\n",
    "    np.save(\"symbols_images.npy\", images)\n",
    "    print(f\"Saved {len(images)} images to symbols_images.npy.\")\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.789703Z",
     "iopub.status.busy": "2025-03-18T10:22:11.789384Z",
     "iopub.status.idle": "2025-03-18T10:22:11.800663Z",
     "shell.execute_reply": "2025-03-18T10:22:11.799841Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.789677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_folds(base_dir=\"/kaggle/input/smai-symbol-data/classification-task\"):\n",
    "    data = {}\n",
    "    pattern = re.compile(r\"(\\d+)\\.png$\")\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        fold = f\"fold-{i}\"\n",
    "        fold_dir = os.path.join(base_dir, fold)\n",
    "        train_csv = os.path.join(fold_dir, \"train.csv\")\n",
    "        test_csv = os.path.join(fold_dir, \"test.csv\")\n",
    "        \n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        test_df = pd.read_csv(test_csv)\n",
    "        \n",
    "        train_df.drop(columns=[\"user_id\"], errors=\"ignore\", inplace=True)\n",
    "        test_df.drop(columns=[\"user_id\"], errors=\"ignore\", inplace=True)\n",
    "        \n",
    "        train_df[\"index\"] = train_df[\"path\"].apply(lambda x: int(pattern.search(x).group(1)))\n",
    "        test_df[\"index\"] = test_df[\"path\"].apply(lambda x: int(pattern.search(x).group(1)))\n",
    "        \n",
    "        # Store processed data\n",
    "        data[fold] = {\n",
    "            \"train\": train_df,\n",
    "            \"test\": test_df\n",
    "        }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.801702Z",
     "iopub.status.busy": "2025-03-18T10:22:11.801415Z",
     "iopub.status.idle": "2025-03-18T10:22:11.815782Z",
     "shell.execute_reply": "2025-03-18T10:22:11.814996Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.801674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_symbols_mapping(symbol_path=\"/kaggle/input/smai-symbols/symbols.csv\"):\n",
    "    \"\"\"Load symbol ID to LaTeX mapping.\"\"\"\n",
    "    symbols_df = pd.read_csv(symbol_path)\n",
    "    unique_symbol_ids = sorted(symbols_df[\"symbol_id\"].unique())\n",
    "    symbol_id_to_index = {symbol_id: i for i, symbol_id in enumerate(unique_symbol_ids)}\n",
    "    index_to_symbol_id = {i: symbol_id for symbol_id, i in symbol_id_to_index.items()}\n",
    "    return symbols_df, symbol_id_to_index, index_to_symbol_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.817102Z",
     "iopub.status.busy": "2025-03-18T10:22:11.816581Z",
     "iopub.status.idle": "2025-03-18T10:22:11.830341Z",
     "shell.execute_reply": "2025-03-18T10:22:11.829633Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.817074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(fold_data, images, symbol_id_to_index, num_classes):\n",
    "    \"\"\"Prepare data for training and testing.\"\"\"\n",
    "    if len(images) == 0:\n",
    "        raise ValueError(\"No images available for data preparation!\")\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _, row in fold_data.iterrows():\n",
    "        idx = row[\"index\"]\n",
    "        if idx >= len(images):\n",
    "            print(f\"Warning: Index {idx} is out of bounds for images array of size {len(images)}\")\n",
    "            continue\n",
    "            \n",
    "        X.append(images[idx].flatten())\n",
    "        y.append(symbol_id_to_index[row[\"symbol_id\"]])\n",
    "    \n",
    "    if not X:\n",
    "        raise ValueError(\"No valid data points were prepared!\")\n",
    "    \n",
    "    X = np.array(X).T / 255.0  # Normalize and reshape to (1024, n_samples)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    y_one_hot = np.zeros((num_classes, y.shape[0]))\n",
    "    y_one_hot[y, np.arange(y.shape[0])] = 1\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y_one_hot = torch.tensor(y_one_hot, dtype=torch.float32)\n",
    "    \n",
    "    return X, y_one_hot, y  # Return y (non-one-hot) for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.831295Z",
     "iopub.status.busy": "2025-03-18T10:22:11.831081Z",
     "iopub.status.idle": "2025-03-18T10:22:11.844537Z",
     "shell.execute_reply": "2025-03-18T10:22:11.843702Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.831277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(fold, images, data, symbol_id_to_index, index_to_symbol_id, \n",
    "                       num_classes, hidden_sizes, activation_func, optimizer, \n",
    "                       learning_rate, epochs, batch_size):\n",
    "    \"\"\"Train and evaluate model for a specific fold and configuration.\"\"\"\n",
    "    if len(images) == 0:\n",
    "        raise ValueError(\"No images available for training!\")\n",
    "        \n",
    "    train_data = data[f\"fold-{fold}\"][\"train\"]\n",
    "    test_data = data[f\"fold-{fold}\"][\"test\"]\n",
    "    \n",
    "    print(f\"Processing fold {fold}:\")\n",
    "    print(f\"  Training data size: {len(train_data)}\")\n",
    "    print(f\"  Testing data size: {len(test_data)}\")\n",
    "    \n",
    "    X_train, y_train_one_hot, y_train = prepare_data(train_data, images, symbol_id_to_index, num_classes)\n",
    "    X_test, y_test_one_hot, y_test = prepare_data(test_data, images, symbol_id_to_index, num_classes)\n",
    "    \n",
    "    print(f\"  Prepared training data shape: {X_train.shape}\")\n",
    "    print(f\"  Prepared testing data shape: {X_test.shape}\")\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = NeuralNetwork()  # Use GPU if available\n",
    "    \n",
    "    # Add layers\n",
    "    model.add_layer(X_train.shape[0], hidden_sizes[0], activation_func)\n",
    "    for i in range(1, len(hidden_sizes)):\n",
    "        model.add_layer(hidden_sizes[i-1], hidden_sizes[i], activation_func)\n",
    "    model.add_layer(hidden_sizes[-1], num_classes, 'softmax')  # Output layer with softmax\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.train(X_train, y_train_one_hot, epochs=epochs, \n",
    "                         batch_size=batch_size, learning_rate=learning_rate, \n",
    "                         loss_function='ce', optimizer=optimizer, verbose=True)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.forwardprop(X_test)\n",
    "    pred_classes = torch.argmax(predictions, dim=0).cpu().numpy()\n",
    "    true_classes = y_test\n",
    "    \n",
    "    # Convert to symbol IDs for reporting\n",
    "    predicted_symbol_ids = [index_to_symbol_id[p] for p in pred_classes]\n",
    "    actual_symbol_ids = [index_to_symbol_id[y] for y in true_classes]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(pred_classes) == np.array(true_classes))\n",
    "    \n",
    "    return accuracy, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.845641Z",
     "iopub.status.busy": "2025-03-18T10:22:11.845362Z",
     "iopub.status.idle": "2025-03-18T10:22:11.859942Z",
     "shell.execute_reply": "2025-03-18T10:22:11.859126Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.845594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_hyperparameter_tuning():\n",
    "    \"\"\"Run hyperparameter tuning with 10-fold validation.\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    images = load_images()\n",
    "    data = load_folds()\n",
    "    symbols_df, symbol_id_to_index, index_to_symbol_id = load_symbols_mapping()\n",
    "    num_classes = len(symbol_id_to_index)\n",
    "    \n",
    "    print(f\"Dataset loaded. Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Define hyperparameters to tune\n",
    "    hidden_sizes_options = [\n",
    "        [512, 256], \n",
    "        [1024, 512]\n",
    "    ]\n",
    "    activation_options = ['sigmoid', 'tanh', 'relu']\n",
    "    optimizer_options = ['Batch', 'SGD', 'Mini_Batch']\n",
    "    learning_rates = [0.01, 0.001]\n",
    "    batch_sizes = [32, 64]  # Only relevant for Mini_Batch\n",
    "    epochs = 20\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Run experiments\n",
    "    for hidden_sizes in hidden_sizes_options:\n",
    "        for activation_func in activation_options:\n",
    "            for optimizer in optimizer_options:\n",
    "                for lr in learning_rates:\n",
    "                    # Skip batch size loop for Batch and SGD optimizers\n",
    "                    if optimizer == 'Batch':\n",
    "                        batch_size_values = [0]  # Not used for Batch\n",
    "                    elif optimizer == 'SGD':\n",
    "                        batch_size_values = [1]  # Not used for SGD\n",
    "                    else:  # Mini_Batch\n",
    "                        batch_size_values = batch_sizes\n",
    "                    \n",
    "                    for batch_size in batch_size_values:\n",
    "                        config_name = f\"hs:{hidden_sizes}_act:{activation_func}_opt:{optimizer}_lr:{lr}\"\n",
    "                        if optimizer == 'Mini_Batch':\n",
    "                            config_name += f\"_bs:{batch_size}\"\n",
    "                        \n",
    "                        print(f\"\\nRunning configuration: {config_name}\")\n",
    "                        \n",
    "                        accuracies = []\n",
    "                        histories = []\n",
    "                        \n",
    "                        # Run for all 10 folds or a subset for testing\n",
    "                        for fold in range(1, 11):\n",
    "                            print(f\"  Processing fold {fold}...\")\n",
    "                            accuracy, history = train_and_evaluate(\n",
    "                                fold, images, data, symbol_id_to_index, index_to_symbol_id,\n",
    "                                num_classes, hidden_sizes, activation_func, optimizer,\n",
    "                                lr, epochs, batch_size if optimizer == 'Mini_Batch' else None\n",
    "                            )\n",
    "                            \n",
    "                            accuracies.append(accuracy)\n",
    "                            histories.append(history)\n",
    "                            \n",
    "                            print(f\"  Fold {fold} accuracy: {accuracy:.4f}\")\n",
    "                        \n",
    "                        results[config_name] = {\n",
    "                            'accuracies': accuracies,\n",
    "                            'mean_accuracy': np.mean(accuracies),\n",
    "                            'std_accuracy': np.std(accuracies),\n",
    "                            'histories': histories,\n",
    "                            'config': {\n",
    "                                'hidden_sizes': hidden_sizes,\n",
    "                                'activation_func': activation_func,\n",
    "                                'optimizer': optimizer,\n",
    "                                'learning_rate': lr,\n",
    "                                'batch_size': batch_size if optimizer == 'Mini_Batch' else None\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        print(f\"Configuration {config_name}:\")\n",
    "                        print(f\"  Mean accuracy: {results[config_name]['mean_accuracy']:.4f}\")\n",
    "                        print(f\"  Std accuracy: {results[config_name]['std_accuracy']:.4f}\")\n",
    "    \n",
    "    with open('mlp_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.862528Z",
     "iopub.status.busy": "2025-03-18T10:22:11.862299Z",
     "iopub.status.idle": "2025-03-18T10:22:11.876203Z",
     "shell.execute_reply": "2025-03-18T10:22:11.875562Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.862510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(results):\n",
    "    \"\"\"Visualize the results of hyperparameter tuning.\"\"\"\n",
    "\n",
    "    sorted_configs = sorted(\n",
    "        results.items(), \n",
    "        key=lambda x: x[1]['mean_accuracy'], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    config_names = [config[:20] + '...' if len(config) > 20 else config for config, _ in sorted_configs[:10]]\n",
    "    means = [res['mean_accuracy'] for _, res in sorted_configs[:10]]\n",
    "    stds = [res['std_accuracy'] for _, res in sorted_configs[:10]]\n",
    "    \n",
    "    plt.bar(config_names, means, yerr=stds, capsize=5)\n",
    "    plt.ylabel('Mean Accuracy')\n",
    "    plt.xlabel('Configuration')\n",
    "    plt.title('Top 10 Configurations by Mean Accuracy')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('top_configurations.png')\n",
    "    \n",
    "    plot_by_category(results, 'activation_func', 'Activation Function')\n",
    "    \n",
    "    plot_by_category(results, 'optimizer', 'Optimizer')\n",
    "    \n",
    "    plot_training_curves(sorted_configs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.877234Z",
     "iopub.status.busy": "2025-03-18T10:22:11.877053Z",
     "iopub.status.idle": "2025-03-18T10:22:11.887878Z",
     "shell.execute_reply": "2025-03-18T10:22:11.887217Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.877218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_by_category(results, category, title):\n",
    "    categories = {}\n",
    "    \n",
    "    for config_name, result in results.items():\n",
    "        cat_value = result['config'][category]\n",
    "        if cat_value not in categories:\n",
    "            categories[cat_value] = []\n",
    "        categories[cat_value].append(result['mean_accuracy'])\n",
    "    \n",
    "    cat_means = {cat: np.mean(values) for cat, values in categories.items()}\n",
    "    cat_stds = {cat: np.std(values) for cat, values in categories.items()}\n",
    "    \n",
    "    # Sort by mean\n",
    "    sorted_cats = sorted(cat_means.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cat_names = [cat for cat, _ in sorted_cats]\n",
    "    means = [mean for _, mean in sorted_cats]\n",
    "    stds = [cat_stds[cat] for cat, _ in sorted_cats]\n",
    "    \n",
    "    plt.bar(cat_names, means, yerr=stds, capsize=5)\n",
    "    plt.ylabel('Mean Accuracy')\n",
    "    plt.xlabel(title)\n",
    "    plt.title(f'Performance by {title}')\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f'performance_by_{category}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.888857Z",
     "iopub.status.busy": "2025-03-18T10:22:11.888642Z",
     "iopub.status.idle": "2025-03-18T10:22:11.904214Z",
     "shell.execute_reply": "2025-03-18T10:22:11.903553Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.888839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_curves(top_configs):\n",
    "    \"\"\"Plot training curves for top configurations.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for idx, (config_name, result) in enumerate(top_configs):\n",
    "        # Average the training curves across folds\n",
    "        avg_history = np.mean(result['histories'], axis=0)\n",
    "        epochs = np.arange(1, len(avg_history) + 1)\n",
    "        \n",
    "        plt.plot(epochs, avg_history, label=f\"Config {idx+1}: {config_name[:30]}...\")\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Curves for Top Configurations')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T10:22:11.905186Z",
     "iopub.status.busy": "2025-03-18T10:22:11.904976Z",
     "iopub.status.idle": "2025-03-18T10:22:11.918105Z",
     "shell.execute_reply": "2025-03-18T10:22:11.917438Z",
     "shell.execute_reply.started": "2025-03-18T10:22:11.905168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def analyze_results(results):\n",
    "    \"\"\"Analyze and report on the results.\"\"\"\n",
    "    # Sort configurations by mean accuracy\n",
    "    sorted_configs = sorted(\n",
    "        results.items(), \n",
    "        key=lambda x: x[1]['mean_accuracy'], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Display top configurations\n",
    "    print(\"\\nTop 5 Configurations:\")\n",
    "    for i, (config_name, result) in enumerate(sorted_configs[:5]):\n",
    "        print(f\"{i+1}. {config_name}\")\n",
    "        print(f\"   Mean Accuracy: {result['mean_accuracy']:.4f}\")\n",
    "        print(f\"   Std Accuracy: {result['std_accuracy']:.4f}\")\n",
    "        print(f\"   Config: {result['config']}\")\n",
    "        print()\n",
    "    \n",
    "    # Calculate average performance by activation function\n",
    "    activations = {}\n",
    "    for config_name, result in results.items():\n",
    "        act = result['config']['activation_func']\n",
    "        if act not in activations:\n",
    "            activations[act] = []\n",
    "        activations[act].append(result['mean_accuracy'])\n",
    "    \n",
    "    print(\"\\nPerformance by Activation Function:\")\n",
    "    for act, accuracies in activations.items():\n",
    "        print(f\"{act}: Mean={np.mean(accuracies):.4f}, Std={np.std(accuracies):.4f}\")\n",
    "    \n",
    "    # Calculate average performance by optimizer\n",
    "    optimizers = {}\n",
    "    for config_name, result in results.items():\n",
    "        opt = result['config']['optimizer']\n",
    "        if opt not in optimizers:\n",
    "            optimizers[opt] = []\n",
    "        optimizers[opt].append(result['mean_accuracy'])\n",
    "    \n",
    "    print(\"\\nPerformance by Optimizer:\")\n",
    "    for opt, accuracies in optimizers.items():\n",
    "        print(f\"{opt}: Mean={np.mean(accuracies):.4f}, Std={np.std(accuracies):.4f}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-18T10:23:22.747Z",
     "iopub.execute_input": "2025-03-18T10:22:11.919117Z",
     "iopub.status.busy": "2025-03-18T10:22:11.918871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline\n",
    "    results = run_hyperparameter_tuning()\n",
    "    visualize_results(results)\n",
    "    analyze_results(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers to Report Questions\n",
    "\n",
    "#### 1. Mean and Standard Deviation Interpretation\n",
    "- The **mean accuracy** reflects the overall performance of a configuration across all folds.\n",
    "- A **higher mean** indicates better general performance.\n",
    "- The **standard deviation** shows how consistent the model performs across different folds.\n",
    "- A **lower standard deviation** indicates more consistent performance across different data splits.\n",
    "\n",
    "#### 2. Impact of High vs. Low Standard Deviation\n",
    "- A **high standard deviation** suggests the model's performance varies significantly depending on the data split,\n",
    "  - which indicates that the model might be sensitive to the specific examples in the training/test sets.\n",
    "  - This reduces confidence in the model's ability to generalize to unseen data.\n",
    "- A **low standard deviation** indicates consistent performance regardless of the data split,\n",
    "  - which increases confidence in the model's generalization capabilities.\n",
    "\n",
    "#### 3. Choosing Between Configurations with Different Means and Standard Deviations\n",
    "- When choosing between a configuration with **slightly higher mean accuracy but significantly higher**\n",
    "  **standard deviation** versus one with **marginally lower mean accuracy but much lower standard deviation,**\n",
    "  - The configuration with the **lower standard deviation** is generally preferable.\n",
    "  - The small sacrifice in average performance is outweighed by the increased reliability and consistency,\n",
    "    - especially important in real-world applications where consistent performance is critical.\n",
    "    - The more stable model is **less likely to fail catastrophically** on certain data distributions.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6893005,
     "sourceId": 11062576,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6893661,
     "sourceId": 11063459,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
